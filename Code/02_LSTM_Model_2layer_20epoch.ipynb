{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d13bc7ad",
   "metadata": {},
   "source": [
    "### Tahap 1: Pemuatan Data dan Inisialisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1c17612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71825494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peringatan: Tidak ada GPU yang terdeteksi. Model akan dilatih menggunakan CPU (jauh lebih lambat).\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Saat ini TensorFlow mencoba mengalokasikan semua memori GPU.\n",
    "    # Kode ini membatasi pertumbuhan memori agar lebih efisien.\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(f\"Berhasil mendeteksi {len(gpus)} GPU: {gpus}\")\n",
    "  except RuntimeError as e:\n",
    "    # Terjadi error jika memory growth sudah di-set sebelumnya\n",
    "    print(e)\n",
    "else:\n",
    "  print(\"Peringatan: Tidak ada GPU yang terdeteksi. Model akan dilatih menggunakan CPU (jauh lebih lambat).\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1297f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Latih dan Uji berhasil dimuat.\n",
      "Fitur yang akan digunakan: ['is_kelas', 'is_kantor', 'is_penelitian', 'avg_temp_previous_hour', 'jam', 'hari_minggu', 'hari_bulan', 'minggu_tahun', 'bulan', 'tahun', 'apakah_akhir_pekan', 'apakah_jam_kerja', 'konsumsi_lag_1_jam', 'konsumsi_lag_24_jam']\n"
     ]
    }
   ],
   "source": [
    "# --- Atur Path (Gunakan kode dari notebook 00 yang sudah direvisi) ---\n",
    "# BASE_DIR, PATH_SPLIT_DATA, PATH_PREDICTIONS, dll.\n",
    "\n",
    "# --- Muat Data ---\n",
    "path_split_data = r'C:\\MyFolder\\Git\\TA_SpatioTemporal\\Data\\split_data' # Path ke folder split_data\n",
    "train_df = pd.read_parquet(os.path.join(path_split_data, 'train_set.parquet'))\n",
    "test_df = pd.read_parquet(os.path.join(path_split_data, 'test_set.parquet'))\n",
    "\n",
    "# --- Definisikan Fitur dan Target ---\n",
    "TARGET = 'konsumsi_energi'\n",
    "# Hapus fitur non-numerik atau yang tidak relevan untuk LSTM (seperti 'apakah_akhir_pekan')\n",
    "FEATURES = [col for col in train_df.columns if col not in ['timestamp', 'meter_id', TARGET]]\n",
    "\n",
    "print(\"Data Latih dan Uji berhasil dimuat.\")\n",
    "print(\"Fitur yang akan digunakan:\", FEATURES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12aa188",
   "metadata": {},
   "source": [
    "### Tahap 2: Pra-pemrosesan Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb174541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memproses Data Latih...\n",
      "Memproses Data Uji...\n",
      "\n",
      "Bentuk data latih (X, y): (282555, 24, 14), (282555, 1)\n",
      "Bentuk data uji (X, y): (47541, 24, 14), (47541, 1)\n"
     ]
    }
   ],
   "source": [
    "# --- Konfigurasi LSTM ---\n",
    "N_PAST = 24 # Jumlah jam masa lalu yang digunakan untuk prediksi (contoh)\n",
    "N_FUTURE = 1 # Memprediksi 1 jam ke depan\n",
    "\n",
    "X_train, y_train = [], []\n",
    "X_test, y_test = [], []\n",
    "scalers = {} # Dictionary untuk menyimpan scaler untuk setiap gedung\n",
    "\n",
    "# --- Proses Data Latih ---\n",
    "print(\"\\nMemproses Data Latih...\")\n",
    "for meter_id, group in train_df.groupby('meter_id'):\n",
    "    # 1. Scaling: Fit dan transform HANYA pada data latih gedung ini\n",
    "    scaler = MinMaxScaler()\n",
    "    group_scaled = scaler.fit_transform(group[FEATURES + [TARGET]])\n",
    "    scalers[meter_id] = scaler # Simpan scaler untuk digunakan pada data uji nanti\n",
    "\n",
    "    # 2. Buat Sekuens\n",
    "    for i in range(N_PAST, len(group_scaled) - N_FUTURE + 1):\n",
    "        X_train.append(group_scaled[i - N_PAST:i, 0:len(FEATURES)])\n",
    "        y_train.append(group_scaled[i + N_FUTURE - 1:i + N_FUTURE, len(FEATURES)])\n",
    "\n",
    "# --- Proses Data Uji ---\n",
    "print(\"Memproses Data Uji...\")\n",
    "# Simpan indeks asli dari data uji untuk merekonstruksi hasil nanti\n",
    "test_indices = []\n",
    "for meter_id, group in test_df.groupby('meter_id'):\n",
    "    if meter_id in scalers:\n",
    "        # 1. Scaling: Gunakan scaler dari data latih (HANYA transform)\n",
    "        scaler = scalers[meter_id]\n",
    "        group_scaled = scaler.transform(group[FEATURES + [TARGET]])\n",
    "\n",
    "        # 2. Buat Sekuens\n",
    "        for i in range(N_PAST, len(group_scaled) - N_FUTURE + 1):\n",
    "            X_test.append(group_scaled[i - N_PAST:i, 0:len(FEATURES)])\n",
    "            y_test.append(group_scaled[i + N_FUTURE - 1:i + N_FUTURE, len(FEATURES)])\n",
    "            # Simpan indeks baris asli dari DataFrame test_df\n",
    "            test_indices.append(group.index[i + N_FUTURE - 1])\n",
    "\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "print(f\"\\nBentuk data latih (X, y): {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Bentuk data uji (X, y): {X_test.shape}, {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a2dffe",
   "metadata": {},
   "source": [
    "### Tahap 3: Pelatihan Model LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a59b9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m20,224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m12,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,673</span> (127.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m32,673\u001b[0m (127.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,673</span> (127.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m32,673\u001b[0m (127.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m 719/7947\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:45\u001b[0m 23ms/step - loss: 0.0197"
     ]
    }
   ],
   "source": [
    "# --- Bangun Arsitektur Model ---\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(32, activation='relu', return_sequences=False))\n",
    "model.add(Dense(y_train.shape[1]))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()\n",
    "\n",
    "# --- Latih Model ---\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.1, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f12377",
   "metadata": {},
   "source": [
    "### Tahap 4: Prediksi dan Rekonstruksi Hasil (Paling Kritis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67728454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1486/1486\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step\n",
      "\n",
      "Evaluasi Final yang Konsisten:\n",
      "MAE: 2.4840\n",
      "R-squared (R²): 0.9579\n",
      "\n",
      "DataFrame hasil LSTM yang sudah sejajar berhasil disimpan.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# --- Tahap 4: Prediksi dan Rekonstruksi Hasil (Metodologi Benar) ---\n",
    "# (Kode ini identik, hanya menggunakan model_1_layer untuk prediksi)\n",
    "# ==============================================================================\n",
    "\n",
    "# --- Lakukan Prediksi ---\n",
    "predictions_scaled = model_1_layer.predict(X_test)\n",
    "\n",
    "# --- Buat DataFrame Hasil yang Solid ---\n",
    "df_hasil = test_df.loc[test_indices].copy()\n",
    "y_pred_inversed = np.array([])\n",
    "y_test_inversed = np.array([])\n",
    "\n",
    "# --- Lakukan inverse transform per gedung ---\n",
    "for meter_id, group in df_hasil.groupby('meter_id'):\n",
    "    if meter_id in scalers:\n",
    "        group_indices = group.index\n",
    "        posisi = [test_indices.index(i) for i in group_indices]\n",
    "        preds_scaled_group = predictions_scaled[posisi]\n",
    "        test_scaled_group = y_test[posisi]\n",
    "        dummy_pred = np.zeros((len(preds_scaled_group), len(FEATURES) + 1)); dummy_pred[:, -1] = preds_scaled_group.ravel()\n",
    "        dummy_test = np.zeros((len(test_scaled_group), len(FEATURES) + 1)); dummy_test[:, -1] = test_scaled_group.ravel()\n",
    "        inversed_preds = scalers[meter_id].inverse_transform(dummy_pred)[:, -1]\n",
    "        inversed_tests = scalers[meter_id].inverse_transform(dummy_test)[:, -1]\n",
    "        y_pred_inversed = np.append(y_pred_inversed, inversed_preds)\n",
    "        y_test_inversed = np.append(y_test_inversed, inversed_tests)\n",
    "\n",
    "# --- Tambahkan kolom hasil ke DataFrame ---\n",
    "df_hasil['prediksi_lstm'] = y_pred_inversed\n",
    "df_hasil.rename(columns={TARGET: 'target_aktual'}, inplace=True)\n",
    "\n",
    "# --- Evaluasi Akhir (DIPERBARUI DENGAN METRIK TAMBAHAN DAN PENJELASAN) ---\n",
    "y_true = df_hasil['target_aktual']\n",
    "y_pred = df_hasil['prediksi_lstm']\n",
    "\n",
    "# Definisikan fungsi untuk MAPE dan sMAPE untuk menghindari pembagian dengan nol\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    # Menambahkan epsilon kecil untuk menghindari pembagian dengan nol\n",
    "    return np.mean(np.abs((y_true - y_pred) / (y_true + 1e-8))) * 100\n",
    "\n",
    "def symmetric_mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    # Menambahkan epsilon kecil untuk menghindari pembagian dengan nol di kedua sisi\n",
    "    return np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred) + 1e-8)) * 100\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "smape = symmetric_mean_absolute_percentage_error(y_true, y_pred)\n",
    "\n",
    "print(f\"\\n--- Evaluasi Final yang Konsisten untuk LSTM 1-Lapis ---\")\n",
    "print(\"\\n\")\n",
    "print(f\"Mean Absolute Error (MAE):       {mae:.4f}\")\n",
    "print(\"--> Penjelasan: Rata-rata selisih absolut antara prediksi dan nilai aktual. Satuannya sama dengan target (kWh). Semakin kecil, semakin baik.\")\n",
    "print(\"\\n\")\n",
    "print(f\"Root Mean Squared Error (RMSE):  {rmse:.4f}\")\n",
    "print(\"--> Penjelasan: Mirip MAE, tapi lebih menghukum kesalahan besar karena dikuadratkan. Satuannya juga kWh. Semakin kecil, semakin baik.\")\n",
    "print(\"\\n\")\n",
    "print(f\"R-squared (R²):                  {r2:.4f}\")\n",
    "print(\"--> Penjelasan: Seberapa baik model menjelaskan variasi data. Nilai 1 berarti prediksi sempurna. Semakin mendekati 1, semakin baik.\")\n",
    "print(\"\\n\")\n",
    "print(f\"Symmetric MAPE (sMAPE):          {smape:.2f}%\")\n",
    "print(\"--> Penjelasan: Versi perbaikan dari MAPE, lebih stabil jika ada nilai aktual mendekati nol. Memberikan error dalam bentuk persentase. Semakin kecil, semakin baik.\")\n",
    "print(\"\\n\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "print(\"--> Peringatan: Nilai MAPE sangat besar! Ini terjadi karena beberapa nilai aktual sangat mendekati nol. Gunakan sMAPE sebagai alternatif yang lebih stabil.\")\n",
    "\n",
    "\n",
    "# --- Simpan Hasil dengan Nama Berbeda ---\n",
    "output_filename = 'lstm_1_layer_results.parquet'\n",
    "df_hasil[['timestamp', 'meter_id', 'target_aktual', 'prediksi_lstm']].to_parquet(\n",
    "    os.path.join(PATH_PREDICTIONS, output_filename), index=False\n",
    ")\n",
    "print(f\"\\nDataFrame hasil LSTM (1 Lapis) yang sudah sejajar berhasil disimpan ke:\\n{os.path.join(PATH_PREDICTIONS, output_filename)}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
