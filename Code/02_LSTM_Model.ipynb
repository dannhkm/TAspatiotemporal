{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d13bc7ad",
   "metadata": {},
   "source": [
    "### A: Persiapan Data untuk LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1297f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data untuk LSTM berhasil dimuat.\n",
      "\n",
      "Data berhasil dinormalisasi.\n",
      "   meter_id           timestamp  konsumsi_energi  konsumsi_lag_1_jam  \\\n",
      "24    BSC A 2024-06-02 00:00:00         0.066347            0.066619   \n",
      "25    BSC A 2024-06-02 01:00:00         0.065227            0.066347   \n",
      "26    BSC A 2024-06-02 02:00:00         0.064165            0.065227   \n",
      "27    BSC A 2024-06-02 03:00:00         0.064281            0.064165   \n",
      "28    BSC A 2024-06-02 04:00:00         0.064731            0.064281   \n",
      "\n",
      "    konsumsi_lag_24_jam  avg_temp_previous_hour       jam  hari_minggu  \\\n",
      "24             0.067487                0.326593  0.000000          1.0   \n",
      "25             0.068094                0.293468  0.043478          1.0   \n",
      "26             0.067262                0.268432  0.086957          1.0   \n",
      "27             0.067268                0.242853  0.130435          1.0   \n",
      "28             0.066485                0.229140  0.173913          1.0   \n",
      "\n",
      "    apakah_jam_kerja  \n",
      "24               0.0  \n",
      "25               0.0  \n",
      "26               0.0  \n",
      "27               0.0  \n",
      "28               0.0  \n",
      "\n",
      "Membuat sekuens dengan melihat 24 jam ke belakang...\n",
      "\n",
      "Pembuatan sekuens selesai.\n",
      "Bentuk data input (X): (331032, 24, 7)\n",
      "Bentuk data target (y): (331032, 1)\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Impor Semua Library yang Dibutuhkan ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- 2. Memuat dan Memilih Fitur ---\n",
    "file_path_features = r'C:\\MyFolder\\Git\\TA_SpatioTemporal\\Data\\parquet\\dataset_final_features_energi_suhu.parquet'\n",
    "df_lstm_input = pd.read_parquet(file_path_features)\n",
    "df_lstm_input.dropna(inplace=True)\n",
    "\n",
    "# Untuk LSTM, kita mulai dengan fitur numerik yang paling penting saja agar tidak terlalu kompleks\n",
    "# Kita akan memasukkan 'meter_id' kembali nanti\n",
    "FEATURES = [\n",
    "    'konsumsi_energi', # Target kita juga menjadi fitur untuk membuat sekuens\n",
    "    'konsumsi_lag_1_jam',\n",
    "    'konsumsi_lag_24_jam',\n",
    "    'avg_temp_previous_hour',\n",
    "    'jam',\n",
    "    'hari_minggu',\n",
    "    'apakah_jam_kerja'\n",
    "]\n",
    "df_lstm_input = df_lstm_input[['meter_id', 'timestamp'] + FEATURES]\n",
    "\n",
    "print(\"Data untuk LSTM berhasil dimuat.\")\n",
    "\n",
    "# --- 3. Normalisasi Data ---\n",
    "# Neural network bekerja paling baik jika semua fitur diskalakan antara 0 dan 1.\n",
    "scaler = MinMaxScaler()\n",
    "# Kita skalakan hanya kolom fitur numerik\n",
    "df_lstm_input[FEATURES] = scaler.fit_transform(df_lstm_input[FEATURES])\n",
    "\n",
    "print(\"\\nData berhasil dinormalisasi.\")\n",
    "print(df_lstm_input.head())\n",
    "\n",
    "# --- 4. Fungsi untuk Membuat Sekuens (Windowing) ---\n",
    "# Ini adalah fungsi inti untuk persiapan data LSTM\n",
    "def create_sequences(data, n_past, n_future, target_col_index):\n",
    "    \"\"\"\n",
    "    Mengubah data time series menjadi format sekuens untuk model LSTM.\n",
    "    n_past: jumlah jam di masa lalu untuk dijadikan input.\n",
    "    n_future: jumlah jam di masa depan untuk diprediksi (kita gunakan 1).\n",
    "    target_col_index: index dari kolom target (konsumsi_energi).\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(n_past, len(data) - n_future + 1):\n",
    "        X.append(data[i - n_past:i, :])\n",
    "        y.append(data[i + n_future - 1:i + n_future, target_col_index])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# --- 5. Terapkan Fungsi Sekuens per Gedung ---\n",
    "# Kita harus membuat sekuens secara terpisah untuk setiap gedung\n",
    "all_X, all_y = [], []\n",
    "n_timesteps = 24  # Model akan melihat 24 jam ke belakang untuk memprediksi 1 jam ke depan\n",
    "n_future = 1      # Memprediksi 1 jam ke depan\n",
    "\n",
    "print(f\"\\nMembuat sekuens dengan melihat {n_timesteps} jam ke belakang...\")\n",
    "\n",
    "for meter in df_lstm_input['meter_id'].unique():\n",
    "    # Ambil data untuk satu gedung\n",
    "    gedung_data = df_lstm_input[df_lstm_input['meter_id'] == meter][FEATURES].values\n",
    "    \n",
    "    # Buat sekuens untuk gedung ini\n",
    "    X_gedung, y_gedung = create_sequences(gedung_data, n_timesteps, n_future, target_col_index=0)\n",
    "    \n",
    "    all_X.append(X_gedung)\n",
    "    all_y.append(y_gedung)\n",
    "\n",
    "# Gabungkan hasil dari semua gedung\n",
    "X_sequences = np.concatenate(all_X)\n",
    "y_sequences = np.concatenate(all_y)\n",
    "\n",
    "print(\"\\nPembuatan sekuens selesai.\")\n",
    "print(f\"Bentuk data input (X): {X_sequences.shape}\") # (jumlah sampel, jam ke belakang, jumlah fitur)\n",
    "print(f\"Bentuk data target (y): {y_sequences.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914cde9f",
   "metadata": {},
   "source": [
    "## Pembagian Data dan Pelatihan Model LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35dfb459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data sekuens berhasil dibagi:\n",
      "Bentuk X_train: (264825, 24, 7), Bentuk y_train: (264825, 1)\n",
      "Bentuk X_test: (66207, 24, 7), Bentuk y_test: (66207, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m11,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,651</span> (45.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,651\u001b[0m (45.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,651</span> (45.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,651\u001b[0m (45.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mulai melatih model LSTM...\n",
      "Epoch 1/20\n",
      "\u001b[1m7449/7449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 7ms/step - loss: 6.1700e-04 - val_loss: 8.6558e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m7449/7449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 6ms/step - loss: 1.0629e-04 - val_loss: 8.4524e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m7449/7449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 7ms/step - loss: 9.6751e-05 - val_loss: 8.0499e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m7449/7449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 7ms/step - loss: 9.3415e-05 - val_loss: 7.6822e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m7449/7449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 8ms/step - loss: 8.7933e-05 - val_loss: 8.1803e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m7449/7449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 8ms/step - loss: 8.3184e-05 - val_loss: 8.1841e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m7449/7449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 8ms/step - loss: 8.2297e-05 - val_loss: 8.0844e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m7449/7449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 7ms/step - loss: 8.0827e-05 - val_loss: 7.4301e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m7449/7449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 7ms/step - loss: 7.8378e-05 - val_loss: 8.0689e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m7449/7449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 7ms/step - loss: 7.7356e-05 - val_loss: 7.4928e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m7449/7449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 7ms/step - loss: 7.7562e-05 - val_loss: 8.3479e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m7449/7449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 8ms/step - loss: 7.4516e-05 - val_loss: 9.0009e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m7449/7449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 8ms/step - loss: 7.6117e-05 - val_loss: 7.9190e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m7449/7449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 8ms/step - loss: 7.4980e-05 - val_loss: 8.2327e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m7449/7449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 8ms/step - loss: 7.4342e-05 - val_loss: 8.4343e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m7449/7449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 8ms/step - loss: 7.1913e-05 - val_loss: 8.0844e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m7449/7449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 8ms/step - loss: 7.2852e-05 - val_loss: 8.1268e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m7449/7449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 8ms/step - loss: 7.1386e-05 - val_loss: 8.1134e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m7449/7449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 8ms/step - loss: 7.3506e-05 - val_loss: 8.4510e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m7449/7449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 8ms/step - loss: 7.1183e-05 - val_loss: 8.2219e-04\n",
      "\n",
      "Model LSTM berhasil dilatih!\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Pembagian Data Sekuens ---\n",
    "# Kita bagi secara sederhana, misal 80% untuk latih, 20% untuk uji\n",
    "train_size = int(len(X_sequences) * 0.8)\n",
    "X_train, X_test = X_sequences[:train_size], X_sequences[train_size:]\n",
    "y_train, y_test = y_sequences[:train_size], y_sequences[train_size:]\n",
    "\n",
    "print(f\"\\nData sekuens berhasil dibagi:\")\n",
    "print(f\"Bentuk X_train: {X_train.shape}, Bentuk y_train: {y_train.shape}\")\n",
    "print(f\"Bentuk X_test: {X_test.shape}, Bentuk y_test: {y_test.shape}\")\n",
    "\n",
    "# --- 2. Membangun Arsitektur Model LSTM ---\n",
    "model_lstm = Sequential([\n",
    "    # Input layer harus tahu bentuk data kita: (jam ke belakang, jumlah fitur)\n",
    "    Input(shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    # Layer LSTM dengan 50 unit memori\n",
    "    LSTM(50, activation='relu'),\n",
    "    # Output layer dengan 1 neuron untuk memprediksi 1 nilai (konsumsi_energi)\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model_lstm.compile(optimizer='adam', loss='mse')\n",
    "model_lstm.summary()\n",
    "\n",
    "# --- 3. Melatih Model ---\n",
    "print(\"\\nMulai melatih model LSTM...\")\n",
    "history = model_lstm.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,  # Jumlah iterasi pelatihan\n",
    "    batch_size=32,\n",
    "    validation_split=0.1, # Gunakan 10% data latih untuk validasi internal\n",
    "    verbose=1\n",
    ")\n",
    "print(\"\\nModel LSTM berhasil dilatih!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4049c330",
   "metadata": {},
   "source": [
    "## C: Evaluasi Kinerja Model LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7dbfa8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2069/2069\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step\n",
      "\n",
      "--- Hasil Evaluasi Model LSTM ---\n",
      "Mean Absolute Error (MAE): 1.00\n",
      "Root Mean Square Error (RMSE): 2.54\n",
      "Symmetric Mean Absolute Percentage Error (sMAPE): 64.00%\n",
      "R-squared (R²): 0.95\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Membuat Prediksi ---\n",
    "predictions_scaled = model_lstm.predict(X_test)\n",
    "\n",
    "# --- 2. Inverse Transform (Mengembalikan ke Skala Asli) ---\n",
    "# Kita harus membuat \"dummy array\" dengan bentuk yang sama seperti saat kita melakukan fit_transform\n",
    "# agar bisa mengembalikan hanya kolom target kita.\n",
    "dummy_array_pred = np.zeros((len(predictions_scaled), len(FEATURES)))\n",
    "dummy_array_pred[:, 0] = predictions_scaled.flatten()\n",
    "predictions_inversed = scaler.inverse_transform(dummy_array_pred)[:, 0]\n",
    "\n",
    "dummy_array_true = np.zeros((len(y_test), len(FEATURES)))\n",
    "dummy_array_true[:, 0] = y_test.flatten()\n",
    "y_test_inversed = scaler.inverse_transform(dummy_array_true)[:, 0]\n",
    "\n",
    "# --- 3. Hitung Metrik Evaluasi pada Data Asli ---\n",
    "def calculate_smape(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    numerator = np.abs(y_pred - y_true)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    ratio = np.divide(numerator, denominator, out=np.zeros_like(denominator), where=denominator!=0)\n",
    "    return np.mean(ratio) * 100\n",
    "\n",
    "mae_lstm = mean_absolute_error(y_test_inversed, predictions_inversed)\n",
    "rmse_lstm = np.sqrt(mean_squared_error(y_test_inversed, predictions_inversed))\n",
    "r2_lstm = r2_score(y_test_inversed, predictions_inversed)\n",
    "smape_lstm = calculate_smape(y_test_inversed, predictions_inversed)\n",
    "\n",
    "print(\"\\n--- Hasil Evaluasi Model LSTM ---\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae_lstm:.2f}\")\n",
    "print(f\"Root Mean Square Error (RMSE): {rmse_lstm:.2f}\")\n",
    "print(f\"Symmetric Mean Absolute Percentage Error (sMAPE): {smape_lstm:.2f}%\")\n",
    "print(f\"R-squared (R²): {r2_lstm:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
