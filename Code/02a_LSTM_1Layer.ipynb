{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7b0d593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Latih dan Uji berhasil dimuat.\n",
      "Fitur yang akan digunakan: ['is_kelas', 'is_kantor', 'is_penelitian', 'avg_temp_previous_hour', 'jam', 'hari_minggu', 'hari_bulan', 'minggu_tahun', 'bulan', 'tahun', 'konsumsi_lag_1_jam', 'konsumsi_lag_24_jam']\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# --- Tahap 1: Inisialisasi dan Pemuatan Data ---\n",
    "# (Kode ini identik dengan yang sudah berhasil sebelumnya)\n",
    "# ==============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "# --- Atur Path ---\n",
    "BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if BASE_DIR not in sys.path:\n",
    "    sys.path.append(BASE_DIR)\n",
    "\n",
    "PATH_SPLIT_DATA = os.path.join(BASE_DIR, 'Data', 'split_data')\n",
    "PATH_PREDICTIONS = os.path.join(BASE_DIR, 'Data', 'predictions')\n",
    "os.makedirs(PATH_PREDICTIONS, exist_ok=True)\n",
    "\n",
    "# --- Muat Data ---\n",
    "train_df = pd.read_parquet(os.path.join(PATH_SPLIT_DATA, 'train_set.parquet'))\n",
    "test_df = pd.read_parquet(os.path.join(PATH_SPLIT_DATA, 'test_set.parquet'))\n",
    "\n",
    "# --- Definisikan Fitur dan Target ---\n",
    "TARGET = 'konsumsi_energi'\n",
    "FEATURES = [col for col in train_df.columns if col not in ['timestamp', 'meter_id', TARGET, 'apakah_akhir_pekan', 'apakah_jam_kerja']]\n",
    "\n",
    "print(\"Data Latih dan Uji berhasil dimuat.\")\n",
    "print(\"Fitur yang akan digunakan:\", FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac599111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memproses Data Latih...\n",
      "Memproses Data Uji...\n",
      "\n",
      "Bentuk data latih (X, y): (282555, 24, 12), (282555, 1)\n",
      "Bentuk data uji (X, y): (47541, 24, 12), (47541, 1)\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# --- Tahap 2: Pra-pemrosesan Data dengan Metodologi yang Benar ---\n",
    "# (Kode ini juga identik, karena metodologi datanya harus sama)\n",
    "# ==============================================================================\n",
    "\n",
    "# --- Konfigurasi LSTM ---\n",
    "N_PAST = 24\n",
    "N_FUTURE = 1\n",
    "\n",
    "X_train, y_train = [], []\n",
    "X_test, y_test = [], []\n",
    "scalers = {}\n",
    "\n",
    "# --- Proses Data Latih ---\n",
    "print(\"\\nMemproses Data Latih...\")\n",
    "for meter_id, group in train_df.groupby('meter_id'):\n",
    "    scaler = MinMaxScaler()\n",
    "    group_scaled = scaler.fit_transform(group[FEATURES + [TARGET]])\n",
    "    scalers[meter_id] = scaler\n",
    "    for i in range(N_PAST, len(group_scaled) - N_FUTURE + 1):\n",
    "        X_train.append(group_scaled[i - N_PAST:i, 0:len(FEATURES)])\n",
    "        y_train.append(group_scaled[i + N_FUTURE - 1:i + N_FUTURE, len(FEATURES)])\n",
    "\n",
    "# --- Proses Data Uji ---\n",
    "print(\"Memproses Data Uji...\")\n",
    "test_indices = []\n",
    "for meter_id, group in test_df.groupby('meter_id'):\n",
    "    if meter_id in scalers:\n",
    "        scaler = scalers[meter_id]\n",
    "        group_scaled = scaler.transform(group[FEATURES + [TARGET]])\n",
    "        for i in range(N_PAST, len(group_scaled) - N_FUTURE + 1):\n",
    "            X_test.append(group_scaled[i - N_PAST:i, 0:len(FEATURES)])\n",
    "            y_test.append(group_scaled[i + N_FUTURE - 1:i + N_FUTURE, len(FEATURES)])\n",
    "            test_indices.append(group.index[i + N_FUTURE - 1])\n",
    "\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "print(f\"\\nBentuk data latih (X, y): {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Bentuk data uji (X, y): {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8aed442b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Danu Hakim\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">19,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m19,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,777</span> (77.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,777\u001b[0m (77.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,777</span> (77.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,777\u001b[0m (77.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m7947/7947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 8ms/step - loss: 0.0067 - val_loss: 0.0042\n",
      "Epoch 2/20\n",
      "\u001b[1m7947/7947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 7ms/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 3/20\n",
      "\u001b[1m7947/7947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 7ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 4/20\n",
      "\u001b[1m7947/7947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 7ms/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 5/20\n",
      "\u001b[1m7947/7947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 7ms/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 6/20\n",
      "\u001b[1m7947/7947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 8ms/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 7/20\n",
      "\u001b[1m7947/7947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 8ms/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 8/20\n",
      "\u001b[1m7947/7947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 8ms/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 9/20\n",
      "\u001b[1m7947/7947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 8ms/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 10/20\n",
      "\u001b[1m7947/7947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 8ms/step - loss: 0.0265 - val_loss: 0.0048\n",
      "Epoch 11/20\n",
      "\u001b[1m7947/7947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 9ms/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 12/20\n",
      "\u001b[1m7947/7947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 8ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 13/20\n",
      "\u001b[1m7947/7947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 8ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 14/20\n",
      "\u001b[1m7947/7947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 8ms/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 15/20\n",
      "\u001b[1m7947/7947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 9ms/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 16/20\n",
      "\u001b[1m7947/7947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 7ms/step - loss: 0.0064 - val_loss: 0.0041\n",
      "Epoch 17/20\n",
      "\u001b[1m7947/7947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 7ms/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 18/20\n",
      "\u001b[1m7947/7947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 9ms/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 19/20\n",
      "\u001b[1m7947/7947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 9ms/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 20/20\n",
      "\u001b[1m7947/7947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 9ms/step - loss: 0.0030 - val_loss: 0.0038\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# --- Tahap 3: Pelatihan Model LSTM (VERSI 1 LAPIS) ---\n",
    "# (INI ADALAH SATU-SATUNYA BAGIAN YANG BERBEDA)\n",
    "# ==============================================================================\n",
    "\n",
    "# --- Bangun Arsitektur Model ---\n",
    "model_1_layer = Sequential()\n",
    "# Kita hanya menggunakan satu lapisan LSTM. return_sequences=False adalah default.\n",
    "# Kita gunakan 64 unit agar sebanding dengan lapisan pertama model 2-lapis.\n",
    "model_1_layer.add(LSTM(64, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "# Langsung ke lapisan output\n",
    "model_1_layer.add(Dense(y_train.shape[1]))\n",
    "\n",
    "model_1_layer.compile(optimizer='adam', loss='mse')\n",
    "model_1_layer.summary()\n",
    "\n",
    "# --- Latih Model ---\n",
    "history_1_layer = model_1_layer.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a9f3b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1486/1486\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step\n",
      "\n",
      "--- Evaluasi Final yang Konsisten untuk LSTM 1-Lapis ---\n",
      "\n",
      "\n",
      "Mean Absolute Error (MAE):       2.3463\n",
      "--> Penjelasan: Rata-rata selisih absolut antara prediksi dan nilai aktual. Satuannya sama dengan target (kWh). Semakin kecil, semakin baik.\n",
      "\n",
      "\n",
      "Root Mean Squared Error (RMSE):  5.4657\n",
      "--> Penjelasan: Mirip MAE, tapi lebih menghukum kesalahan besar karena dikuadratkan. Satuannya juga kWh. Semakin kecil, semakin baik.\n",
      "\n",
      "\n",
      "R-squared (R²):                  0.9593\n",
      "--> Penjelasan: Seberapa baik model menjelaskan variasi data. Nilai 1 berarti prediksi sempurna. Semakin mendekati 1, semakin baik.\n",
      "\n",
      "\n",
      "Symmetric MAPE (sMAPE):          20.57%\n",
      "--> Penjelasan: Versi perbaikan dari MAPE, lebih stabil jika ada nilai aktual mendekati nol. Memberikan error dalam bentuk persentase. Semakin kecil, semakin baik.\n",
      "\n",
      "\n",
      "Mean Absolute Percentage Error (MAPE): 23708976.16%\n",
      "--> Peringatan: Nilai MAPE sangat besar! Ini terjadi karena beberapa nilai aktual sangat mendekati nol. Gunakan sMAPE sebagai alternatif yang lebih stabil.\n",
      "\n",
      "DataFrame hasil LSTM (1 Lapis) yang sudah sejajar berhasil disimpan ke:\n",
      "c:\\MyFolder\\Git\\TA_SpatioTemporal\\Data\\predictions\\lstm_1_layer_results.parquet\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# --- Tahap 4: Prediksi dan Rekonstruksi Hasil (Metodologi Benar) ---\n",
    "# (Kode ini identik, hanya menggunakan model_1_layer untuk prediksi)\n",
    "# ==============================================================================\n",
    "\n",
    "# --- Lakukan Prediksi ---\n",
    "predictions_scaled = model_1_layer.predict(X_test)\n",
    "\n",
    "# --- Buat DataFrame Hasil yang Solid ---\n",
    "df_hasil = test_df.loc[test_indices].copy()\n",
    "y_pred_inversed = np.array([])\n",
    "y_test_inversed = np.array([])\n",
    "\n",
    "# --- Lakukan inverse transform per gedung ---\n",
    "for meter_id, group in df_hasil.groupby('meter_id'):\n",
    "    if meter_id in scalers:\n",
    "        group_indices = group.index\n",
    "        posisi = [test_indices.index(i) for i in group_indices]\n",
    "        preds_scaled_group = predictions_scaled[posisi]\n",
    "        test_scaled_group = y_test[posisi]\n",
    "        dummy_pred = np.zeros((len(preds_scaled_group), len(FEATURES) + 1)); dummy_pred[:, -1] = preds_scaled_group.ravel()\n",
    "        dummy_test = np.zeros((len(test_scaled_group), len(FEATURES) + 1)); dummy_test[:, -1] = test_scaled_group.ravel()\n",
    "        inversed_preds = scalers[meter_id].inverse_transform(dummy_pred)[:, -1]\n",
    "        inversed_tests = scalers[meter_id].inverse_transform(dummy_test)[:, -1]\n",
    "        y_pred_inversed = np.append(y_pred_inversed, inversed_preds)\n",
    "        y_test_inversed = np.append(y_test_inversed, inversed_tests)\n",
    "\n",
    "# --- Tambahkan kolom hasil ke DataFrame ---\n",
    "df_hasil['prediksi_lstm'] = y_pred_inversed\n",
    "df_hasil.rename(columns={TARGET: 'target_aktual'}, inplace=True)\n",
    "\n",
    "# --- Evaluasi Akhir (DIPERBARUI DENGAN METRIK TAMBAHAN DAN PENJELASAN) ---\n",
    "y_true = df_hasil['target_aktual']\n",
    "y_pred = df_hasil['prediksi_lstm']\n",
    "\n",
    "# Definisikan fungsi untuk MAPE dan sMAPE untuk menghindari pembagian dengan nol\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    # Menambahkan epsilon kecil untuk menghindari pembagian dengan nol\n",
    "    return np.mean(np.abs((y_true - y_pred) / (y_true + 1e-8))) * 100\n",
    "\n",
    "def symmetric_mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    # Menambahkan epsilon kecil untuk menghindari pembagian dengan nol di kedua sisi\n",
    "    return np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred) + 1e-8)) * 100\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "smape = symmetric_mean_absolute_percentage_error(y_true, y_pred)\n",
    "\n",
    "print(f\"\\n--- Evaluasi Final yang Konsisten untuk LSTM 1-Lapis ---\")\n",
    "print(\"\\n\")\n",
    "print(f\"Mean Absolute Error (MAE):       {mae:.4f}\")\n",
    "print(\"--> Penjelasan: Rata-rata selisih absolut antara prediksi dan nilai aktual. Satuannya sama dengan target (kWh). Semakin kecil, semakin baik.\")\n",
    "print(\"\\n\")\n",
    "print(f\"Root Mean Squared Error (RMSE):  {rmse:.4f}\")\n",
    "print(\"--> Penjelasan: Mirip MAE, tapi lebih menghukum kesalahan besar karena dikuadratkan. Satuannya juga kWh. Semakin kecil, semakin baik.\")\n",
    "print(\"\\n\")\n",
    "print(f\"R-squared (R²):                  {r2:.4f}\")\n",
    "print(\"--> Penjelasan: Seberapa baik model menjelaskan variasi data. Nilai 1 berarti prediksi sempurna. Semakin mendekati 1, semakin baik.\")\n",
    "print(\"\\n\")\n",
    "print(f\"Symmetric MAPE (sMAPE):          {smape:.2f}%\")\n",
    "print(\"--> Penjelasan: Versi perbaikan dari MAPE, lebih stabil jika ada nilai aktual mendekati nol. Memberikan error dalam bentuk persentase. Semakin kecil, semakin baik.\")\n",
    "print(\"\\n\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "print(\"--> Peringatan: Nilai MAPE sangat besar! Ini terjadi karena beberapa nilai aktual sangat mendekati nol. Gunakan sMAPE sebagai alternatif yang lebih stabil.\")\n",
    "\n",
    "\n",
    "# --- Simpan Hasil dengan Nama Berbeda ---\n",
    "output_filename = 'lstm_1_layer_results.parquet'\n",
    "df_hasil[['timestamp', 'meter_id', 'target_aktual', 'prediksi_lstm']].to_parquet(\n",
    "    os.path.join(PATH_PREDICTIONS, output_filename), index=False\n",
    ")\n",
    "print(f\"\\nDataFrame hasil LSTM (1 Lapis) yang sudah sejajar berhasil disimpan ke:\\n{os.path.join(PATH_PREDICTIONS, output_filename)}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
